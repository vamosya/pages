# -*- coding: utf-8 -*-
"""PR1 Visualización.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1X2PVUEo5SsFyj_PX1pwMfvEbZg8l8QoJ
"""

# Instalar la librería de la API y la de recuperaciones
!pip install garminconnect
!pip install reverse_geocoder

# Librerias necesarias
from garminconnect import Garmin # Para obtener los datos
from getpass import getpass      # Obtener el input de password
import logging                   # loguear en la aplicación
import reverse_geocoder as rg    # Recuperación de localizaciones
import pandas as pd              # Tratamiento de datos en dataframe
import warnings                  # Libraría para omitir los warnings de Jupyter
warnings.filterwarnings("ignore")

# Conexión a Garmin Connect
#paswd = getpass()
paswd = "XXXXXXXX"
client = Garmin("cperaltap@gmail.com", paswd)
client.login()
print("Hola {}! Estás dentro!!".format(client.get_full_name()))

# Decargo y guardo
# Bajar actividades
activities_get = client.get_activities(0,2000) # El tope se puede modificar

# guardo en un dataframe de Pandas
activities = pd.DataFrame(activities_get)

# Muestro las dimensiones del dataframe
dim = activities.shape
print("El df tiene {} sesiones con {} columnas".format(dim[0], dim[1]))

# Guardo el csv
activities.to_csv('activities.csv', header=True, sep = ',')

# Los agrupo en deportes PADRE para que esté más organizado
# Para tener los deportes, primero creo una columna
# Extraer de ActivityType el deporte y añadirlo a columna
sports = []
for i in range(len(activities)):
  sports.append(activities['activityType'][i]['typeKey'])
activities['sport'] = sports

# Creo la columna para deportes padre o principales
sportsParentNumber = []
for i in range(len(activities)):
  sportsParentNumber.append(activities['activityType'][i]['parentTypeId'])
activities['sportParentNumber'] = sportsParentNumber

# Asigno hijos a padres como mejora
activities['sportParent'] = ""
sportParent_dict = {2: 'cycling', 17: 'running_walking', 4: 'rowing_paddling_skating', 26: 'swimming', 1: 'running', 29: 'gym', 165: 'skating', 9: 'walking', 228:'Acuáticos', 219:'Acuáticos'}
for i in range(len(activities)):
  activities['sportParent'][i] = sportParent_dict[activities.sportParentNumber[i]]
  if activities.sport[i] == 'running':
    activities['sportParent'][i] = 'running'
  elif activities.sport[i] == 'hiking':
    activities['sportParent'][i] = 'walking'
  elif activities.sport[i] == 'rowing':
    activities['sportParent'][i] = 'rowing'
  elif activities.sport[i] == 'paddling':
    activities['sportParent'][i] = 'paddle_surf'
  elif activities.sport[i] == 'inline_skating':
    activities['sportParent'][i] = 'inline_skate'
  elif activities.sport[i] == 'cycling':
    activities['sportParent'][i] = 'cycling'
  elif activities.sport[i] == 'walking':
    activities['sportParent'][i] = 'walking'
  elif activities.sport[i] == 'swimming':
    activities['sportParent'][i] = 'swimming'
  elif activities.sport[i] == 'other':
    activities['sportParent'][i] = 'other'
  elif activities.sport[i] == 'fitness_equipment':
    activities['sportParent'][i] = 'gym'
  elif activities.sport[i] == 'stand_up_paddleboarding':
    activities['sportParent'][i] = 'paddle_surf'
  elif activities.sport[i] == 'tennis':
    activities['sportParent'][i] = 'other'
  elif activities.sport[i] == 'boating':
    activities['sportParent'][i] = 'other'
  elif activities.sport[i] == 'rock_climbing':
    activities['sportParent'][i] = 'other'
  elif activities.sport[i] == 'kayaking_v2':
    activities['sportParent'][i] = 'Kayak'
  elif activities.sport[i] == 'snorkeling':
    activities['sportParent'][i] = 'Acuáticos'

activities['sportParent'].unique()

# Veo los que tienen todos sus valores nan y son más de la mitad por lo que los elimino
activities_nan = activities.isnull().sum().sort_values(ascending = False)
activities_nan_dict = activities_nan.to_dict()
lista_no_nan = []
for k, v in activities_nan_dict.items():
  if v != len(activities.index):
    lista_no_nan.append(k)

# Me quedo solo con las que hay en la lista
activities = activities[activities.columns.intersection(lista_no_nan)]
print("Me quedo con {} columnas".format(len(activities.columns)))

# Cambio a las unidades más comunes las columnas de distancia en km, duración en horas y velocidad en km/h
activities['averageSpeedKmh'] = round(activities.averageSpeed*3.6,1)
activities['distanceKm'] = round(activities.distance/1000,1)
activities['durationHours'] = round(activities.duration/3600,2)
activities['durationMinutes'] = round(activities.duration/60,2)

"""Localizaciones"""

# Trabajo con localizaciones

# Redondeo para que haya menos casos diferentes a la hora de calcular las localizaciones
activities = activities.round({'startLatitude': 3})
activities = activities.round({'startLongitude': 3})

# Paso a string para trabajar mejor con los nan
activities['startLatitude'] = activities['startLatitude'].astype(str)
activities['startLongitude'] = activities['startLongitude'].astype(str)

# Sustituyo nan por 0.0
activities['startLatitude'].replace({"nan": "0.0"}, inplace=True)
activities['startLongitude'].replace({"nan": "0.0"}, inplace=True)

# Reseteo el index para facilitar iteración
activities.reset_index(drop=True, inplace=True)

# Creo la tupla necesaria para buscar después
activities['tupleLocation'] = activities[["startLatitude","startLongitude"]].apply(tuple, axis=1)

# Creo lista de ubicaciones únicas para hacer cache
cacheLocs = []
for i in range(len(activities)):
  cacheLocs.append(activities['tupleLocation'][i])
cacheLocs = list(set(cacheLocs))

# Creo el diccionario con estas ubicaciones únicas y su resultado.
tempLocs = {}
for i in range(len(cacheLocs)):
  tempLocs[cacheLocs[i]] = rg.search(cacheLocs[i])
tempLocs

# Inicializo las columnas nuevas
activities['cityLoc'] = ""
activities['provinceLoc'] = ""
activities['regionLoc'] = ""
activities['countryLoc'] = ""

# Itero para ir añadiendo los resultados a las columnas
for i in range(len(activities)):
  coordinates = activities['tupleLocation'][i]
  activities['cityLoc'][i] = tempLocs[coordinates][0]['name']
  activities['regionLoc'][i] = tempLocs[coordinates][0]['admin1']
  activities['provinceLoc'][i] = tempLocs[coordinates][0]['admin2']
  activities['countryLoc'][i] = tempLocs[coordinates][0]['cc']

# Muestro las regiones únicas donde hay actividades
activities.provinceLoc.unique()

# Bajo la lista de códigos de geocodes
url = 'http://download.geonames.org/export/dump/admin2Codes.txt'
provincias = pd.read_csv(url, header=None, sep='\t')
# Guardo las provincias en una lista
lista_provs_geonames = list(provincias[provincias[0].str.startswith('ES.')][2])
lista_provs_geonames
# denominations in the json file
import json

import requests

url = 'https://raw.githubusercontent.com/codeforgermany/click_that_hood/main/public/data/spain-provinces.geojson'
r = requests.get(url, allow_redirects=True)
open('spain-provinces.geojson', 'wb').write(r.content)

communities_geo = r'spain-provinces.geojson'

# open the json file - json.load() methods returns a python dictionary
with open(communities_geo) as communities_file:
    communities_json = json.load(communities_file)

# we loop through the dictionary to obtain the name of the communities in the json file
denominations_json = []
for index in range(len(communities_json['features'])):
    denominations_json.append(communities_json['features'][index]['properties']['name'])

# Tengo guardadas las dos listas de nombres de provincia que tengo que cruzar manualmente para crear un diccionario
prov_dict = {'Province of Toledo':'Toledo',
            'Provincia de Sevilla':'Sevilla',
            'Provincia de Santa Cruz de Tenerife':'Santa Cruz De Tenerife',
            'Provincia de Malaga':'Málaga',
            'Provincia de Las Palmas':'Las Palmas',
            'Provincia de Jaen':'Jaén',
            'Provincia de Huelva':'Huelva',
            'Provincia de Granada':'Granada',
            'Provincia de Cuenca':'Cuenca',
            'Province of Cordoba':'Córdoba',
            'Provincia de Ciudad Real':'Ciudad Real',
            'Provincia de Cadiz':'Cádiz',
            'Provincia de Caceres':'Cáceres',
            'Provincia de Badajoz':'Badajoz',
            'Provincia de Almeria':'Almería',
            'Provincia de Alicante':'Alacant/Alicante',
            'Provincia de Albacete':'Albacete',
            'Provincia de Zaragoza':'Zaragoza',
            'Provincia de Zamora':'Zamora',
            'Bizkaia':'Bizkaia/Vizcaya',
            'Provincia de Valladolid':'Valladolid',
            'Provincia de Teruel':'Teruel',
            'Provincia de Tarragona':'Tarragona',
            'Provincia de Soria':'Soria',
            'Provincia de Segovia':'Segovia',
            'Provincia de Cantabria':'Cantabria',
            'Provincia de Salamanca':'Salamanca',
            'Provincia de Pontevedra':'Pontevedra',
            'Provincia de Palencia':'Palencia',
            'Provincia de Ourense':'Ourense',
            'Provincia de Lugo':'Lugo',
            'Provincia de Leon':'León',
            'Provincia da Coruna':'A Coruña',
            'Provincia de Huesca':'Huesca',
            'Provincia de Guipuzcoa':'Gipuzkoa/Guipúzcoa',
            'Provincia de Guadalajara':'Guadalajara',
            'Provincia de Castello':'Castelló/Castellón',
            'Provincia de Burgos':'Burgos',
            'Provincia de Barcelona':'Barcelona',
            'Provincia de Avila':'Ávila',
            'Provincia de Alava':'Araba/Álava',
            'Provincia de Girona':'Girona',
            'Provincia de Lleida':'Lleida',
            'Provincia de La Rioja':'La Rioja',
            'Provincia de Madrid':'Madrid',
            'Murcia':'Murcia',
            'Provincia de Navarra':'Navarra',
            'Province of Asturias':'Asturias',
            'Illes Balears':'Illes Balears',
            'Ceuta':'Ceuta',
            'Melilla':'Melilla',
            'Provincia de Valencia':'València/Valencia'}

# Ahora itero para crear una columna con el nombre del geojson
activities['provinceGeojson'] = ""
for i in range(len(activities)):
  if activities['countryLoc'][i] != 'ES':
    activities['provinceGeojson'][i] = 'NoSpain'
  else:
    activities['provinceGeojson'][i] = prov_dict[activities['provinceLoc'][i]]

activities.provinceGeojson.unique()

"""Fechas"""

# Paso la columna a datetime
activities.startTimeLocal = pd.to_datetime(activities.startTimeLocal)

# Creo columnas con datos sobre fechas
activities['weekDayDate'] = activities.startTimeLocal.dt.day_name()
activities['hourDate'] = activities.startTimeLocal.dt.hour
activities['monthNameDate'] = activities.startTimeLocal.dt.month_name()
activities['monthNumberDate'] = activities.startTimeLocal.dt.month
activities['yearDate'] = activities.startTimeLocal.dt.year
activities['activityDate'] = activities.startTimeLocal.dt.date
activities['yearDayDate'] = activities.startTimeLocal.dt.dayofyear

pd.set_option('display.max_columns', None)
activities

# Como sigo viendo muchas columnas con Nan, borro las que no tengan al menos un 30% con datos
umbral = len(activities) * 0.3

# Elimino columnas con menos de 30% de datos
activities = activities.dropna(axis=1, thresh=umbral)

# Muestro el DataFrame después de eliminar columnas
print("Me quedo con {} columnas".format(len(activities.columns)))

# Reviso ahora como están de completas las columnas y el tipo de dato de cada una
activities.info()

# Columnas que no me van a aportar o no utilizaré seguro, las elimino.
columnas_del = ['startTimeGMT','movingDuration','elapsedDuration',
'hasPolyline','ownerId','ownerDisplayName','ownerFullName',
'ownerProfileImageUrlSmall','ownerProfileImageUrlMedium',
'ownerProfileImageUrlLarge','userRoles','privacy','userPro',
'hasVideo','timeZoneId','deviceId','manufacturer','splitSummaries',
'purposeful','manualActivity','pr','autoCalcCalories','atpActivity',
'favorite']

# Elimino
activities = activities.drop(columns=columnas_del)

activities.info()

activities.describe()

print("Me quedo con {} columnas".format(len(activities.columns)))

activities.to_csv('activities_garmin.csv')